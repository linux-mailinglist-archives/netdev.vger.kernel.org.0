Return-Path: <netdev+bounces-3219-lists+netdev=lfdr.de@vger.kernel.org>
X-Original-To: lists+netdev@lfdr.de
Delivered-To: lists+netdev@lfdr.de
Received: from sv.mirrors.kernel.org (sv.mirrors.kernel.org [139.178.88.99])
	by mail.lfdr.de (Postfix) with ESMTPS id 4680B7060CD
	for <lists+netdev@lfdr.de>; Wed, 17 May 2023 09:08:56 +0200 (CEST)
Received: from smtp.subspace.kernel.org (wormhole.subspace.kernel.org [52.25.139.140])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by sv.mirrors.kernel.org (Postfix) with ESMTPS id F18FF280FA9
	for <lists+netdev@lfdr.de>; Wed, 17 May 2023 07:08:54 +0000 (UTC)
Received: from localhost.localdomain (localhost.localdomain [127.0.0.1])
	by smtp.subspace.kernel.org (Postfix) with ESMTP id 6B88A8838;
	Wed, 17 May 2023 07:08:36 +0000 (UTC)
X-Original-To: netdev@vger.kernel.org
Received: from lindbergh.monkeyblade.net (lindbergh.monkeyblade.net [23.128.96.19])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by smtp.subspace.kernel.org (Postfix) with ESMTPS id 512BD8835;
	Wed, 17 May 2023 07:08:36 +0000 (UTC)
Received: from out30-101.freemail.mail.aliyun.com (out30-101.freemail.mail.aliyun.com [115.124.30.101])
	by lindbergh.monkeyblade.net (Postfix) with ESMTPS id 4B5D41AD;
	Wed, 17 May 2023 00:08:32 -0700 (PDT)
X-Alimail-AntiSpam:AC=PASS;BC=-1|-1;BR=01201311R171e4;CH=green;DM=||false|;DS=||;FP=0|-1|-1|-1|0|-1|-1|-1;HT=ay29a033018045170;MF=alibuda@linux.alibaba.com;NM=1;PH=DS;RN=23;SR=0;TI=SMTPD_---0VirhhGk_1684307306;
Received: from 30.221.150.40(mailfrom:alibuda@linux.alibaba.com fp:SMTPD_---0VirhhGk_1684307306)
          by smtp.aliyun-inc.com;
          Wed, 17 May 2023 15:08:27 +0800
Message-ID: <beed306a-9f5a-c05b-6f0a-ee28e17f8100@linux.alibaba.com>
Date: Wed, 17 May 2023 15:08:24 +0800
Precedence: bulk
X-Mailing-List: netdev@vger.kernel.org
List-Id: <netdev.vger.kernel.org>
List-Subscribe: <mailto:netdev+subscribe@vger.kernel.org>
List-Unsubscribe: <mailto:netdev+unsubscribe@vger.kernel.org>
MIME-Version: 1.0
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:102.0)
 Gecko/20100101 Thunderbird/102.10.1
Subject: Re: [PATCH bpf-next v1 2/5] net/smc: allow smc to negotiate protocols
 on policies
Content-Language: en-US
To: Martin KaFai Lau <martin.lau@linux.dev>
Cc: kuba@kernel.org, davem@davemloft.net, netdev@vger.kernel.org,
 linux-s390@vger.kernel.org, linux-rdma@vger.kernel.org, bpf@vger.kernel.org,
 kgraul@linux.ibm.com, wenjia@linux.ibm.com, jaka@linux.ibm.com,
 ast@kernel.org, daniel@iogearbox.net, andrii@kernel.org, pabeni@redhat.com,
 song@kernel.org, sdf@google.com, haoluo@google.com, yhs@fb.com,
 edumazet@google.com, john.fastabend@gmail.com, kpsingh@kernel.org,
 jolsa@kernel.org, guwen@linux.alibaba.com
References: <1683872684-64872-1-git-send-email-alibuda@linux.alibaba.com>
 <1683872684-64872-3-git-send-email-alibuda@linux.alibaba.com>
 <0e1656dc-b67c-ec65-83a4-6709fb186061@linux.dev>
From: "D. Wythe" <alibuda@linux.alibaba.com>
In-Reply-To: <0e1656dc-b67c-ec65-83a4-6709fb186061@linux.dev>
Content-Type: text/plain; charset=UTF-8; format=flowed
Content-Transfer-Encoding: 8bit
X-Spam-Status: No, score=-12.6 required=5.0 tests=BAYES_00,
	ENV_AND_HDR_SPF_MATCH,NICE_REPLY_A,RCVD_IN_DNSWL_NONE,
	RCVD_IN_MSPIKE_H2,SPF_HELO_NONE,SPF_PASS,T_SCC_BODY_TEXT_LINE,
	UNPARSEABLE_RELAY,USER_IN_DEF_SPF_WL autolearn=ham autolearn_force=no
	version=3.4.6
X-Spam-Checker-Version: SpamAssassin 3.4.6 (2021-04-09) on
	lindbergh.monkeyblade.net



On 5/16/23 6:52 AM, Martin KaFai Lau wrote:
> On 5/11/23 11:24 PM, D. Wythe wrote:
>> From: "D. Wythe" <alibuda@linux.alibaba.com>
>>
>> As we all know, the SMC protocol is not suitable for all scenarios,
>> especially for short-lived. However, for most applications, they cannot
>> guarantee that there are no such scenarios at all. Therefore, apps
>> may need some specific strategies to decide shall we need to use SMC
>> or not.
>>
>> Just like the congestion control implementation in TCP, this patch
>> provides a generic negotiator implementation. If necessary,
>> we can provide different protocol negotiation strategies for
>> apps based on this implementation.
>>
>> But most importantly, this patch provides the possibility of
>> eBPF injection, allowing users to implement their own protocol
>> negotiation policy in userspace.
>>
>> Signed-off-by: D. Wythe <alibuda@linux.alibaba.com>
>> ---
>> Â  include/net/smc.hÂ Â Â Â Â Â Â  |Â  32 +++++++++++
>> Â  net/MakefileÂ Â Â Â Â Â Â Â Â Â Â Â  |Â Â  1 +
>> Â  net/smc/KconfigÂ Â Â Â Â Â Â Â Â  |Â  11 ++++
>> Â  net/smc/af_smc.cÂ Â Â Â Â Â Â Â  | 134 
>> ++++++++++++++++++++++++++++++++++++++++++++++-
>> Â  net/smc/smc_negotiator.c | 119 
>> +++++++++++++++++++++++++++++++++++++++++
>> Â  net/smc/smc_negotiator.h | 116 
>> ++++++++++++++++++++++++++++++++++++++++
>> Â  6 files changed, 412 insertions(+), 1 deletion(-)
>> Â  create mode 100644 net/smc/smc_negotiator.c
>> Â  create mode 100644 net/smc/smc_negotiator.h
>>
>> diff --git a/include/net/smc.h b/include/net/smc.h
>> index 6d076f5..191061c 100644
>> --- a/include/net/smc.h
>> +++ b/include/net/smc.h
>> @@ -296,6 +296,8 @@ struct smc_sock {Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  /* smc sock 
>> container */
>> Â Â Â Â Â  atomic_tÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â  queued_smc_hs;Â  /* queued smc 
>> handshakes */
>> Â Â Â Â Â  struct inet_connection_sock_af_opsÂ Â Â Â Â Â Â  af_ops;
>> Â Â Â Â Â  const struct inet_connection_sock_af_opsÂ Â Â  *ori_af_ops;
>> +Â Â Â  /* protocol negotiator ops */
>> +Â Â Â  const struct smc_sock_negotiator_ops *negotiator_ops;
>> Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  /* original af ops */
>> Â Â Â Â Â  intÂ Â Â Â Â Â Â Â Â Â Â  sockopt_defer_accept;
>> Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  /* sockopt TCP_DEFER_ACCEPT
>> @@ -316,4 +318,34 @@ struct smc_sock {Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  /* smc sock 
>> container */
>> Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  */
>> Â  };
>> Â  +#ifdef CONFIG_SMC_BPF
>> +/* BPF struct ops for smc protocol negotiator */
>> +struct smc_sock_negotiator_ops {
>> +
>> +Â Â Â  struct list_headÂ Â Â  list;
>> +
>> +Â Â Â  /* ops name */
>> +Â Â Â  charÂ Â Â Â Â Â Â  name[16];
>> +Â Â Â  /* key for name */
>> +Â Â Â  u32Â Â Â Â Â Â Â Â Â Â Â  key;
>> +
>> +Â Â Â  /* init with sk */
>> +Â Â Â  void (*init)(struct sock *sk);
>> +
>> +Â Â Â  /* release with sk */
>> +Â Â Â  void (*release)(struct sock *sk);
>> +
>> +Â Â Â  /* advice for negotiate */
>> +Â Â Â  int (*negotiate)(struct sock *sk);
>> +
>> +Â Â Â  /* info gathering timing */
>> +Â Â Â  void (*collect_info)(struct sock *sk, int timing);
>> +
>> +Â Â Â  /* module owner */
>> +Â Â Â  struct module *owner;
>> +};
>> +#else
>> +struct smc_sock_negotiator_ops {};
>> +#endif
>> +
>> Â  #endifÂ Â Â  /* _SMC_H */
>> diff --git a/net/Makefile b/net/Makefile
>> index 4c4dc53..222916a 100644
>> --- a/net/Makefile
>> +++ b/net/Makefile
>> @@ -52,6 +52,7 @@ obj-$(CONFIG_TIPC)Â Â Â Â Â Â Â  += tipc/
>> Â  obj-$(CONFIG_NETLABEL)Â Â Â Â Â Â Â  += netlabel/
>> Â  obj-$(CONFIG_IUCV)Â Â Â Â Â Â Â  += iucv/
>> Â  obj-$(CONFIG_SMC)Â Â Â Â Â Â Â  += smc/
>> +obj-$(CONFIG_SMC_BPF)Â Â Â Â Â Â Â  += smc/smc_negotiator.o > 
>> obj-$(CONFIG_RFKILL)Â Â Â Â Â Â Â  += rfkill/
>> Â  obj-$(CONFIG_NET_9P)Â Â Â Â Â Â Â  += 9p/
>> Â  obj-$(CONFIG_CAIF)Â Â Â Â Â Â Â  += caif/
>> diff --git a/net/smc/Kconfig b/net/smc/Kconfig
>> index 1ab3c5a..bdcc9f1 100644
>> --- a/net/smc/Kconfig
>> +++ b/net/smc/Kconfig
>> @@ -19,3 +19,14 @@ config SMC_DIAG
>> Â Â Â Â Â Â Â  smcss.
>> Â  Â Â Â Â Â Â Â  if unsure, say Y.
>> +
>> +config SMC_BPF
>> +Â Â Â  bool "SMC: support eBPF" if SMC
>
>
> so smc_negotiator will always be in the kernel image even af_smc is 
> compiled as a module? If the SMC_BPF needs to support af_smc as a 
> module, proper implementation needs to be added to bpf_struct_ops to 
> support module first. It is work-in-progress.
>

smc_negotiator will not no in the kernel image when af_smc is compiled 
as a module,
it's requires config SMC_BPF also sets to be Y,Â  while it's default to 
be N. That's is,
even if af_smc is compiled as a module but with no SMC_BPF set, 
smc_negotiator
doesn't exist anywhere.

>> +Â Â Â  depends on BPF_SYSCALL
>> +Â Â Â  default n
>> +Â Â Â  help
>> +Â Â Â Â Â  Supports eBPF to allows user mode participation in SMC's 
>> protocol process
>> +Â Â Â Â Â  via ebpf programs. Alternatively, obtain information about the 
>> SMC socks
>> +Â Â Â Â Â  through the ebpf program.
>> +
>> +Â Â Â Â Â  If unsure, say N.
>> diff --git a/net/smc/af_smc.c b/net/smc/af_smc.c
>> index 50c38b6..7406fd4 100644
>> --- a/net/smc/af_smc.c
>> +++ b/net/smc/af_smc.c
>> @@ -52,6 +52,7 @@
>> Â  #include "smc_close.h"
>> Â  #include "smc_stats.h"
>> Â  #include "smc_tracepoint.h"
>> +#include "smc_negotiator.h"
>> Â  #include "smc_sysctl.h"
>> Â  Â  static DEFINE_MUTEX(smc_server_lgr_pending);Â Â Â  /* serialize link 
>> group
>> @@ -68,6 +69,119 @@
>> Â  static void smc_tcp_listen_work(struct work_struct *);
>> Â  static void smc_connect_work(struct work_struct *);
>> Â  +#ifdef CONFIG_SMC_BPF
>> +
>> +/* Check if sock should use smc */
>> +int smc_sock_should_select_smc(const struct smc_sock *smc)
>> +{
>> +Â Â Â  const struct smc_sock_negotiator_ops *ops;
>> +Â Â Â  int ret;
>> +
>> +Â Â Â  rcu_read_lock();
>> +Â Â Â  ops = READ_ONCE(smc->negotiator_ops);
>> +
>> +Â Â Â  /* No negotiator_ops supply or no negotiate func set,
>> +Â Â Â Â  * always pass it.
>> +Â Â Â Â  */
>> +Â Â Â  if (!ops || !ops->negotiate) {
>
> A smc_sock_negotiator_ops without ->negotiate? Is it useful at all to 
> allow the register in the first place?
>

You are right, this can be avoid before registration. I'll fix it.

>> +Â Â Â Â Â Â Â  rcu_read_unlock();
>> +Â Â Â Â Â Â Â  return SK_PASS;
>> +Â Â Â  }
>> +
>> +Â Â Â  ret = ops->negotiate((struct sock *)&smc->sk);
>> +Â Â Â  rcu_read_unlock();
>> +Â Â Â  return ret;
>> +}
>> +
>> +void smc_sock_perform_collecting_info(const struct smc_sock *smc, 
>> int timing)
>> +{
>> +Â Â Â  const struct smc_sock_negotiator_ops *ops;
>> +
>> +Â Â Â  rcu_read_lock();
>> +Â Â Â  ops = READ_ONCE(smc->negotiator_ops);
>> +
>> +Â Â Â  if (!ops || !ops->collect_info) {
>> +Â Â Â Â Â Â Â  rcu_read_unlock();
>> +Â Â Â Â Â Â Â  return;
>> +Â Â Â  }
>> +
>> +Â Â Â  ops->collect_info((struct sock *)&smc->sk, timing);
>> +Â Â Â  rcu_read_unlock();
>> +}
>> +
>> +int smc_sock_assign_negotiator_ops(struct smc_sock *smc, const char 
>> *name)
>> +{
>> +Â Â Â  struct smc_sock_negotiator_ops *ops;
>> +Â Â Â  int ret = -EINVAL;
>> +
>> +Â Â Â  /* already set */
>> +Â Â Â  if (READ_ONCE(smc->negotiator_ops))
>> +Â Â Â Â Â Â Â  smc_sock_cleanup_negotiator_ops(smc, /* might be still 
>> referenced */ false);
>> +
>> +Â Â Â  /* Just for clear negotiator_ops */
>> +Â Â Â  if (!name || !strlen(name))
>> +Â Â Â Â Â Â Â  return 0;
>> +
>> +Â Â Â  rcu_read_lock();
>> +Â Â Â  ops = smc_negotiator_ops_get_by_name(name);
>> +Â Â Â  if (likely(ops)) {
>> +Â Â Â Â Â Â Â  if (unlikely(!bpf_try_module_get(ops, ops->owner))) {
>> +Â Â Â Â Â Â Â Â Â Â Â  ret = -EACCES;
>> +Â Â Â Â Â Â Â  } else {
>> +Â Â Â Â Â Â Â Â Â Â Â  WRITE_ONCE(smc->negotiator_ops, ops);
>> +Â Â Â Â Â Â Â Â Â Â Â  /* make sure ops can be seen */
>> +Â Â Â Â Â Â Â Â Â Â Â  smp_wmb();
>
> This rcu_read_lock(), WRITE_ONCE, and smp_wmb() combo looks very 
> suspicious. smc->negotiator_ops is protected by rcu (+refcnt) or 
> lock_sock()?
>

All access to ops is protected by RCU, and there are no lock_sock. 
WRITE_ONCE() and smp_wmb() do
not participate in any guarantee of the availability of ops,Â  The 
purpose to using them is just wish the latest values
can be read as soon as possible , In fact, even if old value is read, 
there will be no problem in logic because all updates
will do synchronize_rcu() and all access to ops is under in rcu_read_lock().

> I am going to stop reviewing here.
>

Hoping my explanation can answer your questions and still looking forward to
your more feedback ðŸ˜.

Best wishes.
D. Wythe

>> +Â Â Â Â Â Â Â Â Â Â Â  if (ops->init)
>> +Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  ops->init(&smc->sk);
>> +Â Â Â Â Â Â Â Â Â Â Â  ret = 0;
>> +Â Â Â Â Â Â Â  }
>> +Â Â Â  }
>> +Â Â Â  rcu_read_unlock();
>> +Â Â Â  return ret;
>> +}
>> +
>> +void smc_sock_cleanup_negotiator_ops(struct smc_sock *smc, bool 
>> no_more)
>> +{
>> +Â Â Â  const struct smc_sock_negotiator_ops *ops;
>> +
>> +Â Â Â  ops = READ_ONCE(smc->negotiator_ops);
>> +
>> +Â Â Â  /* not all smc sock has negotiator_ops */
>> +Â Â Â  if (!ops)
>> +Â Â Â Â Â Â Â  return;
>> +
>> +Â Â Â  might_sleep();
>> +
>> +Â Â Â  /* Just ensure data integrity */
>> +Â Â Â  WRITE_ONCE(smc->negotiator_ops, NULL);
>> +Â Â Â  /* make sure NULL can be seen */
>> +Â Â Â  smp_wmb();
>> +Â Â Â  /* if the socks may have references to the negotiator ops to be 
>> removed.
>> +Â Â Â Â  * it means that we might need to wait for the readers of ops
>> +Â Â Â Â  * to complete. It's slow though.
>> +Â Â Â Â  */
>> +Â Â Â  if (unlikely(!no_more))
>> +Â Â Â Â Â Â Â  synchronize_rcu();
>> +Â Â Â  if (ops->release)
>> +Â Â Â Â Â Â Â  ops->release(&smc->sk);
>> +Â Â Â  bpf_module_put(ops, ops->owner);
>> +}
>> +
>> +void smc_sock_clone_negotiator_ops(struct sock *parent, struct sock 
>> *child)
>> +{
>> +Â Â Â  const struct smc_sock_negotiator_ops *ops;
>> +
>> +Â Â Â  rcu_read_lock();
>> +Â Â Â  ops = READ_ONCE(smc_sk(parent)->negotiator_ops);
>> +Â Â Â  if (ops && bpf_try_module_get(ops, ops->owner)) {
>> +Â Â Â Â Â Â Â  smc_sk(child)->negotiator_ops = ops;
>> +Â Â Â Â Â Â Â  if (ops->init)
>> +Â Â Â Â Â Â Â Â Â Â Â  ops->init(child);
>> +Â Â Â  }
>> +Â Â Â  rcu_read_unlock();
>> +}
>> +#endif
>> +
>> Â  int smc_nl_dump_hs_limitation(struct sk_buff *skb, struct 
>> netlink_callback *cb)
>> Â  {
>> Â Â Â Â Â  struct smc_nl_dmp_ctx *cb_ctx = smc_nl_dmp_ctx(cb);
>> @@ -166,6 +280,9 @@ static bool smc_hs_congested(const struct sock *sk)
>> Â Â Â Â Â  if (workqueue_congested(WORK_CPU_UNBOUND, smc_hs_wq))
>> Â Â Â Â Â Â Â Â Â  return true;
>> Â  +Â Â Â  if (!smc_sock_should_select_smc(smc))
>> +Â Â Â Â Â Â Â  return true;
>> +
>> Â Â Â Â Â  return false;
>> Â  }
>> Â  @@ -320,6 +437,9 @@ static int smc_release(struct socket *sock)
>> Â Â Â Â Â  sock_hold(sk); /* sock_put below */
>> Â Â Â Â Â  smc = smc_sk(sk);
>> Â  +Â Â Â  /* trigger info gathering if needed.*/
>> +Â Â Â  smc_sock_perform_collecting_info(smc, SMC_SOCK_CLOSED_TIMING);
>> +
>> Â Â Â Â Â  old_state = sk->sk_state;
>> Â  Â Â Â Â Â  /* cleanup for a dangling non-blocking connect */
>> @@ -356,6 +476,9 @@ static int smc_release(struct socket *sock)
>> Â  Â  static void smc_destruct(struct sock *sk)
>> Â  {
>> +Â Â Â  /* cleanup negotiator_ops if set */
>> +Â Â Â  smc_sock_cleanup_negotiator_ops(smc_sk(sk), /* no longer used */ 
>> true);
>> +
>> Â Â Â Â Â  if (sk->sk_state != SMC_CLOSED)
>> Â Â Â Â Â Â Â Â Â  return;
>> Â Â Â Â Â  if (!sock_flag(sk, SOCK_DEAD))
>> @@ -1627,7 +1750,14 @@ static int smc_connect(struct socket *sock, 
>> struct sockaddr *addr,
>> Â Â Â Â Â  }
>> Â  Â Â Â Â Â  smc_copy_sock_settings_to_clc(smc);
>> -Â Â Â  tcp_sk(smc->clcsock->sk)->syn_smc = 1;
>> +Â Â Â  /* accept out connection as SMC connection */
>> +Â Â Â  if (smc_sock_should_select_smc(smc) == SK_PASS) {
>> +Â Â Â Â Â Â Â  tcp_sk(smc->clcsock->sk)->syn_smc = 1;
>> +Â Â Â  } else {
>> +Â Â Â Â Â Â Â  tcp_sk(smc->clcsock->sk)->syn_smc = 0;
>> +Â Â Â Â Â Â Â  smc_switch_to_fallback(smc, /* active fallback */ 0);
>> +Â Â Â  }
>> +
>> Â Â Â Â Â  if (smc->connect_nonblock) {
>> Â Â Â Â Â Â Â Â Â  rc = -EALREADY;
>> Â Â Â Â Â Â Â Â Â  goto out;
>> @@ -1679,6 +1809,8 @@ static int smc_clcsock_accept(struct smc_sock 
>> *lsmc, struct smc_sock **new_smc)
>> Â Â Â Â Â  }
>> Â Â Â Â Â  *new_smc = smc_sk(new_sk);
>> Â  +Â Â Â  smc_sock_clone_negotiator_ops(lsk, new_sk);
>> +
>> Â Â Â Â Â  mutex_lock(&lsmc->clcsock_release_lock);
>> Â Â Â Â Â  if (lsmc->clcsock)
>> Â Â Â Â Â Â Â Â Â  rc = kernel_accept(lsmc->clcsock, &new_clcsock, 
>> SOCK_NONBLOCK);
>


