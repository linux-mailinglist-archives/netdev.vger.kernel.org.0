Return-Path: <netdev-owner@vger.kernel.org>
X-Original-To: lists+netdev@lfdr.de
Delivered-To: lists+netdev@lfdr.de
Received: from out1.vger.email (out1.vger.email [IPv6:2620:137:e000::1:20])
	by mail.lfdr.de (Postfix) with ESMTP id 65A4F63D607
	for <lists+netdev@lfdr.de>; Wed, 30 Nov 2022 13:54:50 +0100 (CET)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S234277AbiK3Mys (ORCPT <rfc822;lists+netdev@lfdr.de>);
        Wed, 30 Nov 2022 07:54:48 -0500
Received: from lindbergh.monkeyblade.net ([23.128.96.19]:35092 "EHLO
        lindbergh.monkeyblade.net" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S234005AbiK3Myr (ORCPT
        <rfc822;netdev@vger.kernel.org>); Wed, 30 Nov 2022 07:54:47 -0500
Received: from nautica.notk.org (nautica.notk.org [91.121.71.147])
        by lindbergh.monkeyblade.net (Postfix) with ESMTPS id 7957D2A73E;
        Wed, 30 Nov 2022 04:54:45 -0800 (PST)
Received: by nautica.notk.org (Postfix, from userid 108)
        id 3CE7DC023; Wed, 30 Nov 2022 13:54:52 +0100 (CET)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=codewreck.org; s=2;
        t=1669812892; bh=sh34+7lh2fTDO49r8VZu83HKmBn9XRjerEgAkN6tIEM=;
        h=Date:From:To:Cc:Subject:References:In-Reply-To:From;
        b=R2VgATjg/c6jZM/DKWUgnTwqUhg4Iwzc++IgGL9WrmXAmwyGDAeVgwkxGu6ON/YzN
         TllaExd+gHQjTCxTazomBDH4yZhS7BBgRfn/VCyD6q+nedWv7jz2YYG0jjEEavVbtS
         Lw+LQwVuwOrsNKmr8eEu/rk8xN7DleACoabN+HVIwJOiEh2Ozt9THL81Fh0j8GJ/N8
         b4QisLvJZhhAY6QpGAxNtCxZyY59MOce/5C8J/xr8MvCUoeDZODDfaZ1Fa7nbVj8WM
         lAOBTulcBk4X/mLWHXrrRKdz42ZqMqwTBAiZL9Z6IDaaeLhc6GXjFzP3eTEqPXcCu8
         imVO41MpaZkwg==
X-Spam-Checker-Version: SpamAssassin 3.4.6 (2021-04-09) on
        lindbergh.monkeyblade.net
X-Spam-Level: 
X-Spam-Status: No, score=-2.1 required=5.0 tests=BAYES_00,DKIM_SIGNED,
        DKIM_VALID,DKIM_VALID_AU,DKIM_VALID_EF,SPF_HELO_NONE,SPF_PASS
        autolearn=ham autolearn_force=no version=3.4.6
Received: from odin.codewreck.org (localhost [127.0.0.1])
        by nautica.notk.org (Postfix) with ESMTPS id 90068C009;
        Wed, 30 Nov 2022 13:54:47 +0100 (CET)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=codewreck.org; s=2;
        t=1669812891; bh=sh34+7lh2fTDO49r8VZu83HKmBn9XRjerEgAkN6tIEM=;
        h=Date:From:To:Cc:Subject:References:In-Reply-To:From;
        b=PlvD8W9RyN0fV4z/kaCPpO0kwyi1JN/osxPTTd1SqRNduaoGuq63sXCTO6nNppvqd
         LhGBm/Ka2zP085wZl1iIHCaS8YjYN1ZfqrJvm56AuFD/0e/GXh2Deu9IQ9f9V02bcB
         kT9aiL1C4cqGntPctSSyCju/Wlxv2zLyYHS8Y4pJymXtFBDTRNNTmhBdu5MKsdhv2Z
         /zCWQ31/sFTCx+FG8gwibjWwOXLR2C8Flu7I94Zix2Gh3z+HyI3TEq79gQxnqx1z6e
         8DzVmocSBn4WM14GyUXBZjYdrvOVZETnAVpjD00FF5Ae68jOQSflMEUKwZzZQ6XAdN
         4Pm9oIZvE+wDQ==
Received: from localhost (odin.codewreck.org [local])
        by odin.codewreck.org (OpenSMTPD) with ESMTPA id 3fe9ae05;
        Wed, 30 Nov 2022 12:54:36 +0000 (UTC)
Date:   Wed, 30 Nov 2022 21:54:21 +0900
From:   asmadeus@codewreck.org
To:     Christian Schoenebeck <linux_oss@crudebyte.com>
Cc:     Schspa Shi <schspa@gmail.com>, ericvh@gmail.com, lucho@ionkov.net,
        davem@davemloft.net, edumazet@google.com, kuba@kernel.org,
        pabeni@redhat.com, v9fs-developer@lists.sourceforge.net,
        netdev@vger.kernel.org, linux-kernel@vger.kernel.org,
        syzbot+8f1060e2aaf8ca55220b@syzkaller.appspotmail.com
Subject: Re: [PATCH] 9p: fix crash when transaction killed
Message-ID: <Y4dSfYoU6F8+D8ac@codewreck.org>
References: <20221129162251.90790-1-schspa@gmail.com>
 <m2o7sowzas.fsf@gmail.com>
 <Y4c5N/SAuszTLiEA@codewreck.org>
 <2356667.R3SNuAaExM@silver>
MIME-Version: 1.0
Content-Type: text/plain; charset=utf-8
Content-Disposition: inline
In-Reply-To: <2356667.R3SNuAaExM@silver>
Precedence: bulk
List-ID: <netdev.vger.kernel.org>
X-Mailing-List: netdev@vger.kernel.org

Christian Schoenebeck wrote on Wed, Nov 30, 2022 at 01:43:20PM +0100:
> > > As for the release case, the next request will have the same tag with
> > > high probability. It's better to make the tag value to be an increase
> > > sequence, thus will avoid very much possible req reuse.
> > 
> > I'd love to be able to do this, but it would break some servers that
> > assume tags are small (e.g. using it as an index for a tag array)
> > ... I thought nfs-ganesha was doing this but they properly put in in
> > buckets, so that's one less server to worry about, but I wouldn't put
> > it past some simple servers to do that; having a way to lookup a given
> > tag for flush is an implementation requirement.
> 
> I really think it's time to emit tag number sequentially. If it turns out that
> it's a server that is broken, we could then simply ignore replies with old/
> unknown tag number. It would also help a lot when debugging 9p issues in
> general when you know tag numbers are not re-used (in near future).
> 
> A 9p server must not make any assumptions how tag numbers are generated by
> client, whether dense or sparse, or whatever. If it does then server is
> broken, which is much easier to fix than synchronization issues we have to
> deal with like this one.

Well, it's a one line change: just replace the idr_alloc in the else
branch of p9_tag_alloc with idr_alloc_cyclic.
But linux has an history of not breaking userspace, even if it's broken.
One could argue that the server side of a networked protocol isn't
as tightly coupled but I still think we should be careful with it --
adding a new mount option to rever to the old behaviour at the very
least.

I'm also not convinced it'd fix anything here, we're not talking about a
real server but about a potential attacker -- if a reply comes in with
the next tag while we're allocating it, we'll get the exact same problem
as we have right now.
Frankly, 9p has no security at all so I'm not sure this is something we
really need to worry about, but bugs are bugs so we might as well fix
them if someone has the time for that...

Anyway, I can appreciate that logs will definitely be easier to read, so
an option to voluntarily switch to cyclic allocation would be more than
welcome as a first step and shouldn't be too hard to do...

-- 
Dominique
